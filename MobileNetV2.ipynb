{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "7c7e6293",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import copy\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "fe21ed52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator for dataset\n",
    "def battery_train_gen():\n",
    "    train_x = sio.loadmat(str(Path(data_dir, 'TrainX_IM240')))['TrainX_IM240']\n",
    "    train_y = sio.loadmat(str(Path(data_dir, 'TrainY_IM240')))['TrainY_IM240']\n",
    "    length = len(train_x)\n",
    "    for i in range(length):\n",
    "        x = tf.expand_dims(tf.convert_to_tensor(train_x[i][0], dtype=tf.float32), axis=0)\n",
    "        y = tf.expand_dims(tf.convert_to_tensor(train_y[i], dtype=tf.float32), axis=0)\n",
    "        yield (x, y)\n",
    "        \n",
    "def battery_test_gen():\n",
    "    test_x = sio.loadmat(str(Path(data_dir, 'TestX_IM240')))['TestX_IM240']\n",
    "    test_y = sio.loadmat(str(Path(data_dir, 'TestY_IM240')))['TestY_IM240']\n",
    "    length = len(test_x)\n",
    "    for i in range(length):\n",
    "        x = tf.expand_dims(tf.convert_to_tensor(test_x[i][0], dtype=tf.float32), axis=0)\n",
    "        y = tf.expand_dims(tf.convert_to_tensor(test_y[i], dtype=tf.float32), axis=0)\n",
    "        yield (x, y)\n",
    "        \n",
    "\n",
    "class InvertedResidualLayer2D(keras.layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, strides, expansion_factor=6, trainable=True, name=None, **kwargs):\n",
    "        super(InvertedResidualLayer2D, self).__init__(trainable=trainable, name=name, **kwargs)\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.strides = strides\n",
    "        self.expansion_factor = expansion_factor\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        input_channels = int(input_shape[-1])\n",
    "        self.ptwise_conv1 = keras.layers.Conv2D(int(input_channels * self.expansion_factor),\n",
    "                                               kernel_size=(1,1),\n",
    "                                               strides=(1,1),\n",
    "                                               padding='same',\n",
    "                                               use_bias=False)\n",
    "        \n",
    "        self.dwise = keras.layers.DepthwiseConv2D(kernel_size=self.kernel_size,\n",
    "                                                 strides=self.strides,\n",
    "                                                 padding='same')\n",
    "        \n",
    "        self.ptwise_conv2 = keras.layers.Conv2D(self.filters,\n",
    "                                               kernel_size=(1,1),\n",
    "                                               strides=(1,1),\n",
    "                                               padding='same',\n",
    "                                               use_bias=False)\n",
    "        \n",
    "        self.bn1 = keras.layers.BatchNormalization()\n",
    "        self.bn2 = keras.layers.BatchNormalization()\n",
    "        self.bn3 = keras.layers.BatchNormalization()\n",
    "    \n",
    "    def call(self, input_x):\n",
    "        x = self.ptwise_conv1(input_x)\n",
    "        x = self.bn1(x)\n",
    "        x = tf.nn.relu6(x)\n",
    "        \n",
    "        x = self.dwise(x)\n",
    "        x = self.bn2(x)\n",
    "        x = tf.nn.relu6(x)\n",
    "        \n",
    "        x = self.ptwise_conv2(x)\n",
    "        x = self.bn3(x)\n",
    "        \n",
    "        # residual connection\n",
    "        if input_x.shape[1:] == x.shape[1:]:\n",
    "            x += input_x\n",
    "        \n",
    "        return x\n",
    "            \n",
    "        \n",
    "class MobileNetV2(keras.Model):\n",
    "    def __init__(self, configs):\n",
    "        '''\n",
    "            params:\n",
    "            configs = {\n",
    "                'layers' : [\n",
    "                    [type, expansion_factor, channel, n, stride], format of a layer configuration\n",
    "                    * type\n",
    "                        1 : conv2d\n",
    "                        2 : bottleneck\n",
    "                ]\n",
    "            }\n",
    "        '''\n",
    "        super(MobileNetV2, self).__init__()\n",
    "        \n",
    "        if configs:\n",
    "            self.configs = configs\n",
    "        else:\n",
    "            self.configs = {\n",
    "                'input_size' : (1, 100, 3),\n",
    "                'out_features' : 6,\n",
    "                'kernel_size' : (3, 3),\n",
    "                'strides' : [(0, 0), (1, 1), (2, 2)], \n",
    "                'layers' : [\n",
    "                    [2, 0, 32, 1, 2],\n",
    "                    [2, 1, 16, 1, 1],\n",
    "                    [2, 6, 24, 2, 2],\n",
    "                    [2, 6, 32, 3, 2],\n",
    "                    [2, 6, 64, 4, 2],\n",
    "                    [2, 0, 256, 1, 1],\n",
    "                ]\n",
    "            }\n",
    "        padding = []\n",
    "        for idx, kernel in enumerate(configs['kernel_size']):\n",
    "            if kernel == 1:\n",
    "                padding.append(0)\n",
    "            elif kernel == 3:\n",
    "                padding.append(1)\n",
    "\n",
    "        self.input_size = [[configs['input_size'][0], configs['input_size'][1], configs['input_size'][2]]]\n",
    "        for idx, layer in enumerate(configs['layers']):\n",
    "            next_input = []\n",
    "            next_input.append(int((self.input_size[idx][0] - configs['kernel_size'][0] + 2 * padding[0]) / layer[4]) + 1)\n",
    "            next_input.append(int((self.input_size[idx][1] - configs['kernel_size'][1] + 2 * padding[1]) / layer[4]) + 1)\n",
    "            next_input.append(layer[2])\n",
    "            self.input_size.append(next_input)\n",
    "        \n",
    "        \n",
    "        seq_layers = []\n",
    "        for layer in configs['layers']:\n",
    "            seq_layer = []\n",
    "            stride_index = layer[4]\n",
    "            for i in range(layer[3]):\n",
    "                if i > 0:\n",
    "                    stride_index = 1\n",
    "                # Conv2D\n",
    "                if layer[0] == 1:\n",
    "                    seq_layer.append(\n",
    "                        keras.layers.Conv2D(\n",
    "                            layer[2],\n",
    "                            kernel_size = configs['kernel_size'],\n",
    "                            strides = configs['strides'][stride_index],\n",
    "                            padding = 'same',\n",
    "                            use_bias = False\n",
    "                        )\n",
    "                    )\n",
    "                elif layer[0] == 2:\n",
    "                    seq_layer.append(\n",
    "                        InvertedResidualLayer2D(\n",
    "                            layer[2],\n",
    "                            kernel_size = configs['kernel_size'],\n",
    "                            strides = configs['strides'][stride_index],\n",
    "                            expansion_factor = layer[1]\n",
    "                        )\n",
    "                    )\n",
    "            seq_layer.append(\n",
    "                keras.layers.BatchNormalization()\n",
    "            )\n",
    "            seq_layer.append(\n",
    "                keras.layers.ReLU(max_value=6.0)\n",
    "            )\n",
    "            seq_layers += seq_layer\n",
    "        \n",
    "        \n",
    "        self.encoder = keras.Sequential(seq_layers)\n",
    "        self.out_conv = keras.layers.Conv2D(\n",
    "            configs['out_features'],\n",
    "            kernel_size = (1,1),\n",
    "            strides = (1,1),\n",
    "            padding='same',\n",
    "            use_bias = False\n",
    "        )\n",
    "            \n",
    "    def call(self, inputs):\n",
    "        x = self.encoder(inputs)\n",
    "        x = tf.nn.avg_pool(x, ksize=(self.input_size[-1][0], self.input_size[-1][1]), strides=(1, 1), padding='VALID')\n",
    "        x = self.out_conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "f6e8ba4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "lr = 1.00e-4\n",
    "batch_size = 256\n",
    "\n",
    "configs = {\n",
    "    'input_size' : (1, 100, 3),\n",
    "    'out_features' : 6,\n",
    "    'kernel_size' : (3, 3),\n",
    "    'strides' : [(0, 0), (1, 1), (2, 2)], \n",
    "    'layers' : [\n",
    "        [1, 0, 32, 1, 2],\n",
    "        [2, 1, 16, 1, 1],\n",
    "        [2, 6, 24, 2, 2],\n",
    "        [2, 6, 32, 3, 2],\n",
    "        [2, 6, 64, 4, 2],\n",
    "        [1, 0, 256, 1, 1],\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21160585",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "ded04a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('.', 'data')\n",
    "train_data = tf.data.Dataset.from_generator(\n",
    "    battery_train_gen,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=configs['input_size'], dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(1, configs['out_features']), dtype=tf.float32)\n",
    "    )\n",
    ")\n",
    "\n",
    "train_data = train_data.batch(batch_size)\n",
    "\n",
    "test_data = tf.data.Dataset.from_generator(\n",
    "    battery_test_gen,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(1, 100, 3), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(1, 6), dtype=tf.float32)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02f303d",
   "metadata": {},
   "source": [
    "### Setup Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "df95b2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "    395/Unknown - 87s 203ms/step - loss: 0.0235 - mse: 0.0235"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-442-b9f747a6ebb6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m )\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 3024\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3026\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1961\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 596\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    597\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = MobileNetV2(configs)\n",
    "\n",
    "model.compile(\n",
    "    optimizer = 'Adam',\n",
    "    loss = 'MeanSquaredError',\n",
    "    metrics = ['mse']\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train_data,\n",
    "    batch_size = batch_size,\n",
    "    epochs = epochs, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1135d0c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7e2182",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ec27fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac4fed0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64f6c68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19068aeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f019ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
