{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MobileNetV3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Classification Tasks using Convolutional Neural Network, MobileNet-V3\n",
        "This is tutorial for Kaggle Competition, \"Digit Recognizer\"\n",
        "\n",
        "The main purpose of this work is to verify implemented MobileNetV3."
      ],
      "metadata": {
        "id": "3yea53axQnX1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCWtQ0fgBYCv",
        "outputId": "09326669-14de-4d30-e5ba-3a673a24f27a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.11.1+cu111)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.19.5)\n",
            "Requirement already satisfied: torch==1.10.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.10.0+cu111)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10.0->torchvision) (3.10.0.2)\n",
            "Collecting pytorch-model-summary\n",
            "  Downloading pytorch_model_summary-0.1.2-py3-none-any.whl (9.3 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-model-summary) (4.62.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from pytorch-model-summary) (1.10.0+cu111)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-model-summary) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->pytorch-model-summary) (3.10.0.2)\n",
            "Installing collected packages: pytorch-model-summary\n",
            "Successfully installed pytorch-model-summary-0.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install torch\n",
        "!pip install torchvision\n",
        "!pip install pytorch-model-summary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import os\n",
        "from pathlib import Path\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm.notebook import trange, tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import pytorch_model_summary\n",
        "import time\n",
        "import torchvision"
      ],
      "metadata": {
        "id": "3rKWXjG0E-H5"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "    print('Running on Colab')\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive')\n",
        "    dataDir = Path('/content/gdrive/My Drive', 'dataset')\n",
        "    checkpointDir = Path('/content/gdrive/My Drive', 'checkpoints')\n",
        "else:\n",
        "    dataDir = Path('.', 'dataset')\n",
        "    checkpointDir = Path('.', 'checkpoints', 'fam')\n",
        "\n",
        "dataDir.mkdir(exist_ok=True, parents=True)\n",
        "checkpointDir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "fileDir = Path(dataDir, 'mnist')\n",
        "qFileName = {}\n",
        "qFiles = os.listdir(fileDir)\n",
        "for fName in qFiles:\n",
        "    fNameTmp = fName.lower()\n",
        "    if fNameTmp.find('train') != -1:\n",
        "        qFileName['train'] = fName\n",
        "    elif fNameTmp.find('test') != -1:\n",
        "        qFileName['test'] = fName\n",
        "\n",
        "torch.random.manual_seed(42)\n",
        "np.random.seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9ES6mPSSzJ-",
        "outputId": "02c15ba0-a76e-4318-e0ae-c05cf7505f2c"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on Colab\n",
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convBlock(inp, oup, kernel, stride, padding, bias=True, groups=1):\n",
        "    return nn.Sequential(\n",
        "      nn.Conv2d(inp, oup, kernel, stride, padding, bias=bias, groups=groups),\n",
        "      nn.BatchNorm2d(oup),\n",
        "    )\n",
        "\n",
        "class SqueezeExciteLayer(nn.Module):\n",
        "    def __init__(self, outDim, reductionNum):\n",
        "        super(SqueezeExciteLayer, self).__init__()\n",
        "        hiddenNum = int(outDim / reductionNum)\n",
        "        self.fc1 = nn.Linear(outDim, hiddenNum)\n",
        "        self.fc2 = nn.Linear(hiddenNum, outDim)\n",
        "        self.outDim = outDim\n",
        "\n",
        "    def forward(self, x):\n",
        "        squeeze = x.mean(3).mean(2)\n",
        "        excitation = F.relu(self.fc1(squeeze))\n",
        "        excitation = torch.sigmoid(self.fc2(excitation))\n",
        "        excitation = torch.reshape(excitation, [-1, self.outDim, 1, 1])\n",
        "        return x * excitation\n",
        "\n",
        "class InvertedResidualv3(nn.Module):\n",
        "    def __init__(self, inp, oup, kernel, stride, padding, bias=True, expandRatio=6, reductionNum=4):\n",
        "        super(InvertedResidualv3, self).__init__()\n",
        "        self.stride = stride\n",
        "        self.inp = inp\n",
        "        self.oup = oup\n",
        "        hiddenDim = int(inp * expandRatio)\n",
        "        self.use_res_connect = self.stride == 1 and inp == oup\n",
        "        layers = []        \n",
        "        if expandRatio == 1:\n",
        "            # depthwise\n",
        "            layers.append(convBlock(inp, hiddenDim, kernel, stride, padding, groups=hiddenDim, bias=bias))\n",
        "            layers.append(nn.LeakyReLU())\n",
        "            # pointwise\n",
        "            layers.append(convBlock(hiddenDim, oup, 1, 1, padding, bias=bias))\n",
        "        else:\n",
        "            # pointwise\n",
        "            layers.append(convBlock(inp, hiddenDim, 1, 1, padding, bias=bias))\n",
        "            layers.append(nn.LeakyReLU())\n",
        "            # depthwise\n",
        "            layers.append(convBlock(hiddenDim, hiddenDim, kernel, self.stride, 1, groups=hiddenDim, bias=bias))\n",
        "            layers.append(nn.LeakyReLU())\n",
        "            # squeeze&excite layer\n",
        "            layers.append(SqueezeExciteLayer(hiddenDim, reductionNum))\n",
        "            # pointwise\n",
        "            layers.append(convBlock(hiddenDim, oup, 1, 1, padding, bias=bias))\n",
        "        self.conv = nn.Sequential(*layers)\n",
        "    def forward(self, x):\n",
        "        if self.use_res_connect:\n",
        "            return x + self.conv(x)\n",
        "        else:\n",
        "            return self.conv(x)\n",
        "\n",
        "class MobileNetV3(nn.Module):\n",
        "    def __init__(self, inDim=2, outDim=19):\n",
        "        super(MobileNetV3, self).__init__()\n",
        "        block = InvertedResidualv3\n",
        "        bias = False\n",
        "        kernel = (3,3)\n",
        "        inputChannel = 12\n",
        "        expandRatio = 6\n",
        "        padding='valid'\n",
        "        invertedResidualSetting = [\n",
        "          # t, c, n, s\n",
        "          [6, 12, 2, 2],\n",
        "          [6, 24, 1, 2],\n",
        "        ]\n",
        "\n",
        "        self.features = [convBlock(inDim, inputChannel, kernel, 1, padding, bias=bias)]\n",
        "        for t, c, n, s in invertedResidualSetting:\n",
        "            outputChannel = c\n",
        "            for i in range(n):\n",
        "                if i == 0:\n",
        "                    self.features.append(block(inputChannel, outputChannel, kernel, s, padding, bias, expandRatio=t))\n",
        "                else:\n",
        "                    self.features.append(block(inputChannel, outputChannel, kernel, 1, padding, bias, expandRatio=t))\n",
        "                inputChannel = outputChannel\n",
        "        self.features = nn.Sequential(*self.features)\n",
        "        self.conv1 = nn.Sequential(\n",
        "            convBlock(inputChannel, inputChannel * expandRatio, 1, 1, padding),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(inputChannel * expandRatio, inputChannel, 1, 1, padding),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "        self.fc1 = nn.Linear(inputChannel, outDim)\n",
        "        self._initialize_weights()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.conv1(x)\n",
        "        x = x.mean(3, keepdim=True).mean(2, keepdim=True)\n",
        "        x = self.conv2(x)\n",
        "        return F.softmax(self.fc1(torch.squeeze(x)), dim=1)\n",
        "        \n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                # nn.init.t(m.weight, gain=0.1)\n",
        "                nn.init.normal_(m.weight, std=0.1)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight)"
      ],
      "metadata": {
        "id": "eVatwHV9G_58"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DigitDataset(Dataset):\n",
        "    def __init__(self, csv_data, transform, phase='training'):\n",
        "        self.csv_data = csv_data\n",
        "        self.transform = transform\n",
        "        raw_tensor = torch.tensor(csv_data)\n",
        "        self.phase = phase\n",
        "        if self.phase == 'training':\n",
        "            self.data, self.labels = raw_tensor[:, 1:].view(-1, 28, 28), raw_tensor[:, 0]\n",
        "        if self.phase == 'testing':\n",
        "            # test dataset does not have label, only digit data\n",
        "            self.data = raw_tensor.view(-1, 28, 28)\n",
        "                \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        if self.phase == 'training':\n",
        "            return self.transform(self.data[idx]), self.labels[idx]\n",
        "        if self.phase == 'testing':\n",
        "            # idx+1 is not used, but it is real label of the test dataset\n",
        "            return self.transform(self.data[idx]), (idx+1)\n",
        "        \n",
        "def training(model, datasets, datasets_size, optimizer, scheduler, epochs=10):\n",
        "    # Conduct train and valid per a epoch\n",
        "    phases = ['train', 'valid']\n",
        "    \n",
        "    best_valid_accuracy = -1.0\n",
        "    \n",
        "    training_loss = []\n",
        "    validation_loss = []\n",
        "        \n",
        "    for epoch in range(epochs):                \n",
        "        print(f'-------------- Epoch {epoch+1} --------------')        \n",
        "        \n",
        "        for phase in phases:\n",
        "            epoch_begin = time.time()\n",
        "            epoch_accuracy = 0.0\n",
        "            epoch_losses = 0.0\n",
        "            \n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "                \n",
        "            if phase == 'valid':\n",
        "                model.eval()\n",
        "                \n",
        "            for data in datasets[phase]:\n",
        "                # Init weights for each batch dataset\n",
        "                if phase == 'train':\n",
        "                    optimizer.zero_grad()\n",
        "                    \n",
        "                inputs, labels = data\n",
        "                # to use nll_loss, labels should be LongTensor\n",
        "                labels = labels.type(torch.LongTensor)\n",
        "                if torch.cuda.is_available():\n",
        "                    inputs, labels = inputs.cuda(), labels.cuda()\n",
        "                \n",
        "                output = model(inputs)\n",
        "                _, preds = torch.max(output, 1)\n",
        "                loss = F.nll_loss(output, labels)\n",
        "                \n",
        "                # add .detach() because of the out of memory issue. (grow computational graph)\n",
        "                epoch_losses += loss.sum().detach()\n",
        "                epoch_accuracy += torch.sum(preds == labels).detach().item()\n",
        "                if phase == 'train':\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "                        \n",
        "            epoch_losses = epoch_losses / datasets_size[phase]\n",
        "            epoch_accuracy = 100. * epoch_accuracy / datasets_size[phase]\n",
        "            print(f'{phase} Epoch Losses : {epoch_losses:.5f} :: Accuracy : {epoch_accuracy:.5f} :: Time : {(time.time() - epoch_begin):.4f}s')\n",
        "            \n",
        "            if phase == 'train':\n",
        "                training_loss.append(epoch_losses)\n",
        "            if phase == 'valid':\n",
        "                if best_valid_accuracy < epoch_accuracy:\n",
        "                    best_valid_accuracy = epoch_accuracy\n",
        "                    torch.save(model.state_dict(), 'final_model.pth')\n",
        "                validation_loss.append(epoch_losses)\n",
        "        \n",
        "        scheduler.step()\n",
        "    return training_loss, validation_loss\n",
        "\n",
        "def testing(model, dataset):\n",
        "    result = []\n",
        "    if torch.cuda.is_available():\n",
        "            model.cuda()\n",
        "    for data in dataset:\n",
        "        inputs, labels = data\n",
        "        if torch.cuda.is_available():\n",
        "            inputs, labels = inputs.cuda(), labels.cuda()\n",
        "        output = model(inputs)\n",
        "        _, preds = torch.max(output, 1)\n",
        "        # testing data is sequential, so label is unnecessary thing\n",
        "        result += [int(element) for element in preds.tolist()]\n",
        "    return result"
      ],
      "metadata": {
        "id": "sXs_8z0uFA0D"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "batch_size = 64\n",
        "learning_rate = 1e-4\n",
        "inputDim = 1\n",
        "outDim = 10"
      ],
      "metadata": {
        "id": "Ze1EdGwIulKi"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MobileNetV3(inputDim, outDim)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-2)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=50)\n",
        "\n",
        "dummy_input = torch.zeros(batch_size, inputDim, 28, 28)\n",
        "print(pytorch_model_summary.summary(model, dummy_input))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdKmMnhVxpTR",
        "outputId": "fc05b95f-82e5-4c4e-8674-82f79f4187a7"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------------\n",
            "           Layer (type)         Output Shape         Param #     Tr. Param #\n",
            "=============================================================================\n",
            "               Conv2d-1     [64, 12, 26, 26]             108             108\n",
            "          BatchNorm2d-2     [64, 12, 26, 26]              24              24\n",
            "   InvertedResidualv3-3     [64, 12, 13, 13]           5,370           5,370\n",
            "   InvertedResidualv3-4     [64, 12, 13, 13]           5,370           5,370\n",
            "   InvertedResidualv3-5       [64, 24, 7, 7]           6,258           6,258\n",
            "               Conv2d-6      [64, 144, 7, 7]           3,600           3,600\n",
            "          BatchNorm2d-7      [64, 144, 7, 7]             288             288\n",
            "            LeakyReLU-8      [64, 144, 7, 7]               0               0\n",
            "               Conv2d-9       [64, 24, 1, 1]           3,480           3,480\n",
            "           LeakyReLU-10       [64, 24, 1, 1]               0               0\n",
            "              Linear-11             [64, 10]             250             250\n",
            "=============================================================================\n",
            "Total params: 24,748\n",
            "Trainable params: 24,748\n",
            "Non-trainable params: 0\n",
            "-----------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "\n",
        "transforms = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToPILImage(),\n",
        "    torchvision.transforms.Resize((28, 28)),\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize([0.5], [0.5])\n",
        "])\n",
        "\n",
        "# Load data\n",
        "valid_fraction = 0.1\n",
        "\n",
        "train_file = pd.read_csv(Path(fileDir, qFileName['train']))\n",
        "# convert dataframe of pandas into numpy array\n",
        "train_file = train_file.to_numpy().astype('uint8')\n",
        "\n",
        "boundary = int(len(train_file) * (1 - valid_fraction))\n",
        "\n",
        "train_data = DigitDataset(train_file[:boundary], transforms, phase='training')\n",
        "valid_data = DigitDataset(train_file[boundary:], transforms, phase='training')\n",
        "\n",
        "train_data_loader = DataLoader(\n",
        "    train_data,\n",
        "    batch_size = 64,\n",
        "    shuffle = True,\n",
        "    num_workers = 3\n",
        ")\n",
        "\n",
        "valid_data_loader = DataLoader(\n",
        "    valid_data,\n",
        "    batch_size = 64,\n",
        "    shuffle = True,\n",
        "    num_workers = 3\n",
        ")\n",
        "\n",
        "datasets = {'train' : train_data_loader, 'valid' : valid_data_loader}\n",
        "datasets_size = {'train' : len(train_data_loader.dataset), 'valid' : len(valid_data_loader.dataset)}"
      ],
      "metadata": {
        "id": "y04N4rNTbSIl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48489c1e-d496-4e22-af7e-d2d64cfc13a4"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss, valid_loss = training(model, datasets, datasets_size, optimizer, scheduler, epochs=epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fe2kjaPQbhCe",
        "outputId": "79ab0d35-c409-40f5-9f28-97c8d1f0250e"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------- Epoch 0 --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Epoch Losses : -0.00469 :: Accuracy : 32.27249 :: Time : 133.3693s\n",
            "valid Epoch Losses : -0.00673 :: Accuracy : 46.02381 :: Time : 4.9538s\n",
            "-------------- Epoch 1 --------------\n",
            "train Epoch Losses : -0.00825 :: Accuracy : 55.50794 :: Time : 139.5313s\n",
            "valid Epoch Losses : -0.00961 :: Accuracy : 62.90476 :: Time : 5.1903s\n",
            "-------------- Epoch 2 --------------\n",
            "train Epoch Losses : -0.00965 :: Accuracy : 63.29630 :: Time : 138.5436s\n",
            "valid Epoch Losses : -0.01000 :: Accuracy : 65.16667 :: Time : 4.9324s\n",
            "-------------- Epoch 3 --------------\n",
            "train Epoch Losses : -0.00996 :: Accuracy : 64.98942 :: Time : 138.5485s\n",
            "valid Epoch Losses : -0.01024 :: Accuracy : 66.23810 :: Time : 5.0353s\n",
            "-------------- Epoch 4 --------------\n",
            "train Epoch Losses : -0.01060 :: Accuracy : 69.83069 :: Time : 139.9407s\n",
            "valid Epoch Losses : -0.01120 :: Accuracy : 73.45238 :: Time : 5.0024s\n",
            "-------------- Epoch 5 --------------\n",
            "train Epoch Losses : -0.01131 :: Accuracy : 74.31746 :: Time : 139.1041s\n",
            "valid Epoch Losses : -0.01152 :: Accuracy : 75.11905 :: Time : 4.9399s\n",
            "-------------- Epoch 6 --------------\n",
            "train Epoch Losses : -0.01141 :: Accuracy : 74.82011 :: Time : 140.5317s\n",
            "valid Epoch Losses : -0.01153 :: Accuracy : 75.16667 :: Time : 4.9537s\n",
            "-------------- Epoch 7 --------------\n",
            "train Epoch Losses : -0.01148 :: Accuracy : 75.30159 :: Time : 139.1373s\n",
            "valid Epoch Losses : -0.01169 :: Accuracy : 76.26190 :: Time : 4.9396s\n",
            "-------------- Epoch 8 --------------\n",
            "train Epoch Losses : -0.01153 :: Accuracy : 75.81217 :: Time : 138.4939s\n",
            "valid Epoch Losses : -0.01168 :: Accuracy : 76.21429 :: Time : 4.9601s\n",
            "-------------- Epoch 9 --------------\n",
            "train Epoch Losses : -0.01156 :: Accuracy : 76.15873 :: Time : 139.4576s\n",
            "valid Epoch Losses : -0.01162 :: Accuracy : 76.14286 :: Time : 5.0065s\n",
            "-------------- Epoch 10 --------------\n",
            "train Epoch Losses : -0.01159 :: Accuracy : 76.44444 :: Time : 139.9713s\n",
            "valid Epoch Losses : -0.01176 :: Accuracy : 77.64286 :: Time : 4.9869s\n",
            "-------------- Epoch 11 --------------\n",
            "train Epoch Losses : -0.01224 :: Accuracy : 83.29630 :: Time : 140.2856s\n",
            "valid Epoch Losses : -0.01268 :: Accuracy : 84.66667 :: Time : 4.9648s\n",
            "-------------- Epoch 12 --------------\n",
            "train Epoch Losses : -0.01268 :: Accuracy : 85.24868 :: Time : 139.3519s\n",
            "valid Epoch Losses : -0.01277 :: Accuracy : 84.97619 :: Time : 5.0204s\n",
            "-------------- Epoch 13 --------------\n",
            "train Epoch Losses : -0.01275 :: Accuracy : 85.69312 :: Time : 139.8445s\n",
            "valid Epoch Losses : -0.01277 :: Accuracy : 85.28571 :: Time : 4.9047s\n",
            "-------------- Epoch 14 --------------\n",
            "train Epoch Losses : -0.01278 :: Accuracy : 85.97884 :: Time : 139.9507s\n",
            "valid Epoch Losses : -0.01275 :: Accuracy : 85.47619 :: Time : 5.0455s\n",
            "-------------- Epoch 15 --------------\n",
            "train Epoch Losses : -0.01279 :: Accuracy : 86.23280 :: Time : 141.7605s\n",
            "valid Epoch Losses : -0.01272 :: Accuracy : 85.54762 :: Time : 4.9760s\n",
            "-------------- Epoch 16 --------------\n",
            "train Epoch Losses : -0.01279 :: Accuracy : 86.32540 :: Time : 142.7439s\n",
            "valid Epoch Losses : -0.01283 :: Accuracy : 85.78571 :: Time : 5.0435s\n",
            "-------------- Epoch 17 --------------\n",
            "train Epoch Losses : -0.01279 :: Accuracy : 86.42063 :: Time : 140.9609s\n",
            "valid Epoch Losses : -0.01288 :: Accuracy : 86.02381 :: Time : 5.1047s\n",
            "-------------- Epoch 18 --------------\n",
            "train Epoch Losses : -0.01281 :: Accuracy : 86.61640 :: Time : 139.4592s\n",
            "valid Epoch Losses : -0.01278 :: Accuracy : 85.73810 :: Time : 5.0398s\n",
            "-------------- Epoch 19 --------------\n",
            "train Epoch Losses : -0.01282 :: Accuracy : 86.59259 :: Time : 139.5994s\n",
            "valid Epoch Losses : -0.01281 :: Accuracy : 86.04762 :: Time : 5.2131s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Draw loss graph for training\n",
        "epoch_x = range(1, epochs + 1)\n",
        "plt.plot(epoch_x, train_loss, 'r', epoch_x, valid_loss, 'b')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "Uao_lTxdbnHW",
        "outputId": "a6b2383d-43e6-4c71-cb67-cbe5db279a8f"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load test dataset\n",
        "test_file = pd.read_csv(Path(fileDir, qFileName['test']))\n",
        "test_file = test_file.to_numpy().astype('uint8')\n",
        "\n",
        "test_data = DigitDataset(test_file, transforms, phase='testing')\n",
        "\n",
        "test_data_loader = DataLoader(\n",
        "    test_data,\n",
        "    batch_size = 16,\n",
        "    num_workers = 3\n",
        ")"
      ],
      "metadata": {
        "id": "EG6IpPKDV2sR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f29f6dc-cc78-48a5-9ae9-4f2c7ad7d63f"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load best model\n",
        "model = MobileNetV3(inputDim, outDim)\n",
        "model.load_state_dict(torch.load('final_model.pth'))\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "\n",
        "# Test the model\n",
        "result = testing(model, test_data_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFx3Igyp6VVt",
        "outputId": "d3fb89ca-58cb-482d-dd79-9b0e6915a8e8"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Export result as csv file in form of Kaggle\n",
        "submission = pd.DataFrame({\n",
        "    'ImageId' : range(1, len(result) + 1),\n",
        "    'Label' : result\n",
        "},columns=['ImageId', 'Label'])\n",
        "submission.to_csv('submission.csv', index=False)"
      ],
      "metadata": {
        "id": "7n5UWE0k6W0E"
      },
      "execution_count": 153,
      "outputs": []
    }
  ]
}